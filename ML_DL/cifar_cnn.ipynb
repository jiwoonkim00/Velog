{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf790609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79c9c081",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 준비\n",
    "#-------------------------------------------------------------------------------\n",
    "# CIFAR-10 데이터셋을 위한 변환(transform) 정의\n",
    "# 이미지를 Tensor로 변환하고, 정규화(normalize)합니다.\n",
    "# CIFAR-10 이미지의 각 채널에 대한 평균과 표준편차는 [0.5, 0.5, 0.5] 입니다.\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# 학습용 데이터셋 로드 (CIFAR-10)\n",
    "# CIFAR-100으로 변경하려면 torchvision.datasets.CIFAR100으로 변경하세요.\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# 테스트용 데이터셋 로드\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2784096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 신경망 모델 정의 (간단한 CNN)\n",
    "#-------------------------------------------------------------------------------\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 3-channel (RGB) images, 6 output channels, 5x5 square convolution\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0702f10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 손실 함수 및 옵티마이저 정의\n",
    "#-------------------------------------------------------------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9d53e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습을 시작합니다...\n",
      "[1,   200] loss: 2.306\n",
      "[1,   400] loss: 2.303\n",
      "[1,   600] loss: 2.300\n",
      "[2,   200] loss: 2.290\n",
      "[2,   400] loss: 2.271\n",
      "[2,   600] loss: 2.199\n",
      "[3,   200] loss: 1.975\n",
      "[3,   400] loss: 1.923\n",
      "[3,   600] loss: 1.883\n",
      "[4,   200] loss: 1.792\n",
      "[4,   400] loss: 1.740\n",
      "[4,   600] loss: 1.695\n",
      "[5,   200] loss: 1.630\n",
      "[5,   400] loss: 1.612\n",
      "[5,   600] loss: 1.589\n",
      "[6,   200] loss: 1.524\n",
      "[6,   400] loss: 1.528\n",
      "[6,   600] loss: 1.505\n",
      "[7,   200] loss: 1.466\n",
      "[7,   400] loss: 1.450\n",
      "[7,   600] loss: 1.429\n",
      "[8,   200] loss: 1.399\n",
      "[8,   400] loss: 1.408\n",
      "[8,   600] loss: 1.378\n",
      "[9,   200] loss: 1.354\n",
      "[9,   400] loss: 1.353\n",
      "[9,   600] loss: 1.326\n",
      "[10,   200] loss: 1.313\n",
      "[10,   400] loss: 1.308\n",
      "[10,   600] loss: 1.297\n",
      "학습 완료\n"
     ]
    }
   ],
   "source": [
    "# 4. 모델 학습\n",
    "#-------------------------------------------------------------------------------\n",
    "print(\"학습을 시작합니다...\")\n",
    "for epoch in range(10):  # 10 에포크 동안 학습합니다.\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 200:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('학습 완료')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8584529e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터셋에서의 정확도: 53 %\n",
      "'plane' 분류의 정확도: 58.6 %\n",
      "'car' 분류의 정확도: 66.4 %\n",
      "'bird' 분류의 정확도: 32.8 %\n",
      "'cat' 분류의 정확도: 32.1 %\n",
      "'deer' 분류의 정확도: 40.2 %\n",
      "'dog' 분류의 정확도: 53.2 %\n",
      "'frog' 분류의 정확도: 72.1 %\n",
      "'horse' 분류의 정확도: 61.7 %\n",
      "'ship' 분류의 정확도: 73.0 %\n",
      "'truck' 분류의 정확도: 48.7 %\n"
     ]
    }
   ],
   "source": [
    "# 6. 모델 평가\n",
    "#-------------------------------------------------------------------------------\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'테스트 데이터셋에서의 정확도: {100 * correct // total} %')\n",
    "\n",
    "# 각 분류(class)에 대한 정확도 출력\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f\"'{classname}' 분류의 정확도: {accuracy:.1f} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551287ae",
   "metadata": {},
   "source": [
    "전이학습으로 CIFAR-10/100 분류 (ResNet 등 유명 아키텍처)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15950b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/jiwoonkim/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "/tmp/ipykernel_31318/973171444.py:105: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device.type==\"cuda\"))\n",
      "/tmp/ipykernel_31318/973171444.py:116: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 01] train loss 0.9654 | acc 0.8109 | lr 2.99e-04\n",
      "          >> valid loss 0.7473 | acc 0.9078\n",
      "          ** checkpoint saved: resnet18_cifar10.pt (acc=0.9078)\n",
      "[Epoch 02] train loss 0.8088 | acc 0.8785 | lr 2.97e-04\n",
      "          >> valid loss 0.7173 | acc 0.9164\n",
      "          ** checkpoint saved: resnet18_cifar10.pt (acc=0.9164)\n",
      "[Epoch 03] train loss 0.7653 | acc 0.8954 | lr 2.93e-04\n",
      "          >> valid loss 0.6873 | acc 0.9283\n",
      "          ** checkpoint saved: resnet18_cifar10.pt (acc=0.9283)\n",
      "[Epoch 04] train loss 0.7352 | acc 0.9082 | lr 2.87e-04\n",
      "          >> valid loss 0.6776 | acc 0.9333\n",
      "          ** checkpoint saved: resnet18_cifar10.pt (acc=0.9333)\n",
      "[Epoch 05] train loss 0.7158 | acc 0.9152 | lr 2.80e-04\n",
      "          >> valid loss 0.6538 | acc 0.9427\n",
      "          ** checkpoint saved: resnet18_cifar10.pt (acc=0.9427)\n",
      "[Epoch 06] train loss 0.6986 | acc 0.9231 | lr 2.71e-04\n",
      "          >> valid loss 0.6510 | acc 0.9406\n",
      "[Epoch 07] train loss 0.6815 | acc 0.9297 | lr 2.61e-04\n",
      "          >> valid loss 0.6379 | acc 0.9461\n",
      "          ** checkpoint saved: resnet18_cifar10.pt (acc=0.9461)\n",
      "[Epoch 08] train loss 0.6737 | acc 0.9339 | lr 2.50e-04\n",
      "          >> valid loss 0.6347 | acc 0.9479\n",
      "          ** checkpoint saved: resnet18_cifar10.pt (acc=0.9479)\n",
      "[Epoch 09] train loss 0.6584 | acc 0.9403 | lr 2.38e-04\n",
      "          >> valid loss 0.6259 | acc 0.9508\n",
      "          ** checkpoint saved: resnet18_cifar10.pt (acc=0.9508)\n",
      "[Epoch 10] train loss 0.6484 | acc 0.9436 | lr 2.25e-04\n",
      "          >> valid loss 0.6233 | acc 0.9517\n",
      "          ** checkpoint saved: resnet18_cifar10.pt (acc=0.9517)\n",
      "[Epoch 11] train loss 0.6385 | acc 0.9469 | lr 2.11e-04\n",
      "          >> valid loss 0.6153 | acc 0.9540\n",
      "          ** checkpoint saved: resnet18_cifar10.pt (acc=0.9540)\n",
      "[Epoch 12] train loss 0.6317 | acc 0.9499 | lr 1.96e-04\n",
      "          >> valid loss 0.6220 | acc 0.9527\n",
      "[Epoch 13] train loss 0.6219 | acc 0.9548 | lr 1.81e-04\n",
      "          >> valid loss 0.6113 | acc 0.9549\n",
      "          ** checkpoint saved: resnet18_cifar10.pt (acc=0.9549)\n",
      "[Epoch 14] train loss 0.6165 | acc 0.9563 | lr 1.66e-04\n",
      "          >> valid loss 0.6122 | acc 0.9553\n",
      "          ** checkpoint saved: resnet18_cifar10.pt (acc=0.9553)\n",
      "[Epoch 15] train loss 0.6069 | acc 0.9605 | lr 1.50e-04\n",
      "          >> valid loss 0.6138 | acc 0.9570\n",
      "          ** checkpoint saved: resnet18_cifar10.pt (acc=0.9570)\n",
      "[Epoch 16] train loss 0.6033 | acc 0.9611 | lr 1.34e-04\n",
      "          >> valid loss 0.6121 | acc 0.9550\n",
      "[Epoch 17] train loss 0.5929 | acc 0.9654 | lr 1.19e-04\n",
      "          >> valid loss 0.6056 | acc 0.9578\n",
      "          ** checkpoint saved: resnet18_cifar10.pt (acc=0.9578)\n",
      "[Epoch 18] train loss 0.5893 | acc 0.9670 | lr 1.04e-04\n",
      "          >> valid loss 0.5988 | acc 0.9596\n",
      "          ** checkpoint saved: resnet18_cifar10.pt (acc=0.9596)\n",
      "[Epoch 19] train loss 0.5817 | acc 0.9695 | lr 8.90e-05\n",
      "          >> valid loss 0.5964 | acc 0.9609\n",
      "          ** checkpoint saved: resnet18_cifar10.pt (acc=0.9609)\n",
      "[Epoch 20] train loss 0.5799 | acc 0.9709 | lr 7.50e-05\n",
      "          >> valid loss 0.5924 | acc 0.9623\n",
      "          ** checkpoint saved: resnet18_cifar10.pt (acc=0.9623)\n",
      "[Epoch 21] train loss 0.5737 | acc 0.9728 | lr 6.18e-05\n",
      "          >> valid loss 0.5864 | acc 0.9657\n",
      "          ** checkpoint saved: resnet18_cifar10.pt (acc=0.9657)\n",
      "[Epoch 22] train loss 0.5675 | acc 0.9759 | lr 4.96e-05\n",
      "          >> valid loss 0.5864 | acc 0.9640\n",
      "[Epoch 23] train loss 0.5670 | acc 0.9755 | lr 3.85e-05\n",
      "          >> valid loss 0.5854 | acc 0.9662\n",
      "          ** checkpoint saved: resnet18_cifar10.pt (acc=0.9662)\n",
      "[Epoch 24] train loss 0.5632 | acc 0.9776 | lr 2.86e-05\n",
      "          >> valid loss 0.5843 | acc 0.9654\n",
      "[Epoch 25] train loss 0.5617 | acc 0.9775 | lr 2.01e-05\n",
      "          >> valid loss 0.5806 | acc 0.9649\n",
      "[Epoch 26] train loss 0.5595 | acc 0.9784 | lr 1.30e-05\n",
      "          >> valid loss 0.5810 | acc 0.9667\n",
      "          ** checkpoint saved: resnet18_cifar10.pt (acc=0.9667)\n",
      "[Epoch 27] train loss 0.5583 | acc 0.9793 | lr 7.34e-06\n",
      "          >> valid loss 0.5798 | acc 0.9677\n",
      "          ** checkpoint saved: resnet18_cifar10.pt (acc=0.9677)\n",
      "[Epoch 28] train loss 0.5561 | acc 0.9799 | lr 3.28e-06\n",
      "          >> valid loss 0.5785 | acc 0.9686\n",
      "          ** checkpoint saved: resnet18_cifar10.pt (acc=0.9686)\n",
      "[Epoch 29] train loss 0.5560 | acc 0.9798 | lr 8.22e-07\n",
      "          >> valid loss 0.5790 | acc 0.9686\n",
      "[Epoch 30] train loss 0.5551 | acc 0.9802 | lr 0.00e+00\n",
      "          >> valid loss 0.5788 | acc 0.9683\n",
      "\n",
      "Best Val Acc: 0.9686\n",
      "\n",
      "Classification report (top-10 shown if CIFAR100):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       plane     0.9780    0.9780    0.9780      1000\n",
      "         car     0.9761    0.9820    0.9791      1000\n",
      "        bird     0.9658    0.9590    0.9624      1000\n",
      "         cat     0.9495    0.9030    0.9257      1000\n",
      "        deer     0.9684    0.9800    0.9742      1000\n",
      "         dog     0.9307    0.9530    0.9417      1000\n",
      "        frog     0.9754    0.9900    0.9826      1000\n",
      "       horse     0.9860    0.9830    0.9845      1000\n",
      "        ship     0.9790    0.9800    0.9795      1000\n",
      "       truck     0.9740    0.9750    0.9745      1000\n",
      "\n",
      "    accuracy                         0.9683     10000\n",
      "   macro avg     0.9683    0.9683    0.9682     10000\n",
      "weighted avg     0.9683    0.9683    0.9682     10000\n",
      "\n",
      " plane: 97.8%\n",
      "   car: 98.2%\n",
      "  bird: 95.9%\n",
      "   cat: 90.3%\n",
      "  deer: 98.0%\n",
      "   dog: 95.3%\n",
      "  frog: 99.0%\n",
      " horse: 98.3%\n",
      "  ship: 98.0%\n",
      " truck: 97.5%\n"
     ]
    }
   ],
   "source": [
    "# pip install torch torchvision --upgrade\n",
    "\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np, time\n",
    "\n",
    "# ==============================\n",
    "# 0) 설정\n",
    "# ==============================\n",
    "DATASET = \"cifar10\"   # \"cifar10\" 또는 \"cifar100\"\n",
    "ARCH    = \"resnet18\"  # \"resnet18\",\"vgg16_bn\",\"densenet121\",\"efficientnet_b0\"\n",
    "BATCH_TRAIN, BATCH_TEST = 128, 256\n",
    "EPOCHS = 30\n",
    "LR = 3e-4\n",
    "WEIGHT_DECAY = 5e-4\n",
    "LABEL_SMOOTH = 0.1     # CrossEntropy(label_smoothing)\n",
    "FREEZE_BACKBONE = False  # True면 head만 학습(빠름, 과적합 낮음)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "# ==============================\n",
    "# 1) 데이터\n",
    "#  - Pretrained 모델은 ImageNet 통계/해상도에 맞추는 게 유리\n",
    "#    -> 224로 리사이즈 + ImageNet mean/std 정규화\n",
    "# ==============================\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
    "\n",
    "train_tfms = T.Compose([\n",
    "    T.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.AutoAugment(T.AutoAugmentPolicy.CIFAR10),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "test_tfms = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "if DATASET == \"cifar10\":\n",
    "    trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True,  download=True, transform=train_tfms)\n",
    "    testset  = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=test_tfms)\n",
    "    NUM_CLASSES = 10\n",
    "    CLASSES = ('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')\n",
    "else:\n",
    "    trainset = torchvision.datasets.CIFAR100(root=\"./data\", train=True,  download=True, transform=train_tfms)\n",
    "    testset  = torchvision.datasets.CIFAR100(root=\"./data\", train=False, download=True, transform=test_tfms)\n",
    "    NUM_CLASSES = 100\n",
    "    CLASSES = tuple([str(i) for i in range(NUM_CLASSES)])\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_TRAIN, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "testloader  = DataLoader(testset,  batch_size=BATCH_TEST,  shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "# ==============================\n",
    "# 2) 모델 불러오기 (+헤드 교체)\n",
    "# ==============================\n",
    "def build_model(arch: str, num_classes: int):\n",
    "    if arch == \"resnet18\":\n",
    "        m = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        in_f = m.fc.in_features\n",
    "        m.fc = nn.Linear(in_f, num_classes)\n",
    "    elif arch == \"vgg16_bn\":\n",
    "        m = models.vgg16_bn(weights=models.VGG16_BN_Weights.IMAGENET1K_V1)\n",
    "        in_f = m.classifier[-1].in_features\n",
    "        m.classifier[-1] = nn.Linear(in_f, num_classes)\n",
    "    elif arch == \"densenet121\":\n",
    "        m = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
    "        in_f = m.classifier.in_features\n",
    "        m.classifier = nn.Linear(in_f, num_classes)\n",
    "    elif arch == \"efficientnet_b0\":\n",
    "        m = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "        in_f = m.classifier[-1].in_features\n",
    "        m.classifier[-1] = nn.Linear(in_f, num_classes)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown arch\")\n",
    "    return m\n",
    "\n",
    "model = build_model(ARCH, NUM_CLASSES).to(device)\n",
    "\n",
    "# (선택) 백본 프리즈\n",
    "if FREEZE_BACKBONE:\n",
    "    for name, p in model.named_parameters():\n",
    "        if \"fc\" in name or \"classifier\" in name:\n",
    "            p.requires_grad = True\n",
    "        else:\n",
    "            p.requires_grad = False\n",
    "\n",
    "# ==============================\n",
    "# 3) 손실/옵티마이저/스케줄러\n",
    "# ==============================\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTH)\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                              lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(device.type==\"cuda\"))\n",
    "\n",
    "# ==============================\n",
    "# 4) 학습/평가 함수\n",
    "# ==============================\n",
    "def train_one_epoch(epoch):\n",
    "    model.train()\n",
    "    t0, running, correct, n = time.time(), 0.0, 0, 0\n",
    "    for x, y in trainloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running += loss.item() * y.size(0)\n",
    "        pred = logits.argmax(1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        n += y.size(0)\n",
    "    scheduler.step()\n",
    "    print(f\"[Epoch {epoch:02d}] train loss {running/n:.4f} | acc {correct/n:.4f} | lr {scheduler.get_last_lr()[0]:.2e}\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    total_loss, correct, n = 0.0, 0, 0\n",
    "    y_true, y_pred = [], []\n",
    "    for x, y in testloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        pred = logits.argmax(1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        n += y.size(0)\n",
    "        y_true.append(y.cpu().numpy()); y_pred.append(pred.cpu().numpy())\n",
    "    y_true = np.concatenate(y_true); y_pred = np.concatenate(y_pred)\n",
    "    acc = correct / n\n",
    "    return total_loss/n, acc, y_true, y_pred\n",
    "\n",
    "# ==============================\n",
    "# 5) 학습 루프\n",
    "# ==============================\n",
    "best_acc, best_path = 0.0, f\"{ARCH}_{DATASET}.pt\"\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    train_one_epoch(ep)\n",
    "    val_loss, val_acc, y_true, y_pred = evaluate()\n",
    "    print(f\"          >> valid loss {val_loss:.4f} | acc {val_acc:.4f}\")\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_path)\n",
    "        print(f\"          ** checkpoint saved: {best_path} (acc={best_acc:.4f})\")\n",
    "\n",
    "print(\"\\nBest Val Acc:\", best_acc)\n",
    "model.load_state_dict(torch.load(best_path, map_location=device))\n",
    "\n",
    "# ==============================\n",
    "# 6) 클래스별 정확도/리포트\n",
    "# ==============================\n",
    "print(\"\\nClassification report (top-10 shown if CIFAR100):\")\n",
    "print(classification_report(y_true, y_pred, target_names=(CLASSES if len(CLASSES)==10 else None), digits=4))\n",
    "\n",
    "# per-class accuracy (CIFAR-10만 표기)\n",
    "if len(CLASSES) == 10:\n",
    "    per_cls_total = {c:0 for c in CLASSES}\n",
    "    per_cls_ok    = {c:0 for c in CLASSES}\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        c = CLASSES[t]\n",
    "        per_cls_total[c] += 1\n",
    "        if t == p: per_cls_ok[c] += 1\n",
    "    for c in CLASSES:\n",
    "        print(f\"{c:>6s}: {100*per_cls_ok[c]/per_cls_total[c]:.1f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
